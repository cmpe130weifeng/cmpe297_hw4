{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn_O6jrlWj0T",
        "outputId": "5f04bc6f-39bd-4cfb-b432-c1a48a1769aa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!tar xvf \"/content/drive/MyDrive/Cmpe_deep_learning/images.tar\" -C \"/content/drive/MyDrive/Cmpe_deep_learning/Multitask learning & Meta learning/images\""
      ],
      "metadata": {
        "id": "qp-LwP7FySpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "z6MLQDWi5WzZ"
      },
      "outputs": [],
      "source": [
        "# import necessary libraries\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import collections"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "metadata": {
        "id": "vAaecsiuQREE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to read csv files\n",
        "def read_csv(csv_path):\n",
        "    # create a dictionary to store the data\n",
        "    dict = collections.defaultdict(list)\n",
        "    df = pd.read_csv(csv_path)\n",
        "    for index,row in df.iterrows():\n",
        "        dict[row[\"label\"]].append(row[\"filename\"])\n",
        "    return dict"
      ],
      "metadata": {
        "id": "34gtTr6CQRM9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv_path = '/content/drive/MyDrive/Cmpe_deep_learning/Multitask learning & Meta learning/data/train.csv'\n",
        "val_csv_path = '/content/drive/MyDrive/Cmpe_deep_learning/Multitask learning & Meta learning/data/val.csv'\n",
        "test_csv_path = '/content/drive/MyDrive/Cmpe_deep_learning/Multitask learning & Meta learning/data/test.csv'"
      ],
      "metadata": {
        "id": "3taTfY6FWr8l"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if you want to run it in your local mechine,\n",
        "# please download data from: https://github.com/cmpe130weifeng/cmpe297_hw4/tree/main/prototypical%20networks/data\n",
        "train_dict = read_csv(train_csv_path)\n",
        "val_dict = read_csv(val_csv_path)\n",
        "test_dict = read_csv(test_csv_path)"
      ],
      "metadata": {
        "id": "6YEpsw3SQRKE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resize image to smaller size, it would save spaces \n",
        "resize_transform = transforms.Resize(84)"
      ],
      "metadata": {
        "id": "Pk-HyCLhQRBU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# you can download data from: https://www.kaggle.com/datasets/zcyzhchyu/mini-imagenet\n",
        "img_root_dir = '/content/drive/MyDrive/Cmpe_deep_learning/Multitask learning & Meta learning/images'\n",
        "\n",
        "# for each image, resize it to 84*84 and convert it to a numpy array\n",
        "def build_data(data_dict):\n",
        "    datas = []\n",
        "    labels = []\n",
        "    label_index = 0\n",
        "    for label in data_dict.keys(): # loop to labels\n",
        "        for path in data_dict[label]: # loop to based on label's name\n",
        "            img_path = os.path.join(img_root_dir, path) \n",
        "            img = Image.open(img_path) # read image\n",
        "            img = resize_transform(img) # transform image\n",
        "            datas.append(img) \n",
        "            labels.append(label_index)\n",
        "\n",
        "        label_index += 1\n",
        "    return {\"datas\":datas,\"labels\":labels}"
      ],
      "metadata": {
        "id": "b7Fzr-D_QQ-W"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build training, testing & validation data\n",
        "train_data = build_data(train_dict)\n",
        "val_data = build_data(val_dict)\n",
        "test_data = build_data(test_dict)"
      ],
      "metadata": {
        "id": "aXd4BudMQQ6-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torch\n",
        "\n",
        "# for few-shot learning\n",
        "class CategoriesSampler():\n",
        "    \"\"\"\n",
        "        purpose is to create K_way*(N_support+N_query) and its corresponding index\n",
        "    \"\"\"\n",
        "    def __init__(self, data, n_batch, K_way, N_per):\n",
        "        self.n_batch = n_batch\n",
        "        self.K_way = K_way\n",
        "        self.N_per = N_per\n",
        "        labels = np.array(data[\"labels\"]) # [0,0,0,0,1,1,1,1,2,2,2,2……]\n",
        "        self.index = [] # save label's index\n",
        "        for i in range(max(labels)+1): # for each label\n",
        "            ind = np.argwhere(labels == i).reshape(-1) # find the index of the label\n",
        "            self.index.append(torch.from_numpy(ind))   \n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_batch\n",
        "    \n",
        "    def __iter__(self):\n",
        "        for i_batch in range(self.n_batch):  # for each batch \n",
        "            batch = []\n",
        "            classes = torch.randperm(len(self.index))[:self.K_way] # randomly select support set & query set\n",
        "            for c in classes:\n",
        "                l = self.index[c] # find the index of the label\n",
        "                pos = torch.randperm(len(l))[:self.N_per] # randomly select N_per images\n",
        "                batch.append(l[pos]) \n",
        "\n",
        "            batch = torch.stack(batch).reshape(-1)\n",
        "            yield batch"
      ],
      "metadata": {
        "id": "rw_N4U1cQQ30"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class to create dataset\n",
        "class MiniImageNet(Dataset):\n",
        "\n",
        "    def __init__(self, data):\n",
        "\n",
        "        self.datas = data[\"datas\"]\n",
        "        self.labels = data[\"labels\"]\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.CenterCrop(84),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.datas)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        img, label = self.datas[i], self.labels[i]\n",
        "        return self.transform(img), label"
      ],
      "metadata": {
        "id": "KU8Vg-4cQQ1F"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# class to create model\n",
        "class CNN_Net(nn.Module):\n",
        "    \"\"\"\n",
        "        to extract features\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim):\n",
        "        super(CNN_Net, self).__init__()\n",
        "        \n",
        "        self.input_dim = input_dim\n",
        "\n",
        "         # create a conv block\n",
        "        def conv_block(in_channel,out_channel): \n",
        "            # create a sequential model\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_channel, out_channel, 3,padding=1), # convelutional layer\n",
        "                nn.BatchNorm2d(out_channel), # batch normalization\n",
        "                nn.ReLU(), # activation func\n",
        "                nn.MaxPool2d(2) # max pooling\n",
        "            )\n",
        "        self.encoder = nn.Sequential(\n",
        "            conv_block(input_dim,64), \n",
        "            conv_block(64,64), # you can see size is not reduced\n",
        "            conv_block(64,64),\n",
        "            conv_block(64,64),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "lgn-FvHqjAMg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prototypical networks\n",
        "class Prototypicl_Net():\n",
        "    def __init__(self, input_dim):\n",
        "\n",
        "        self.device = torch.device(\n",
        "            \"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.z_dim = 1600 # feature dimension\n",
        "        self.cnn_net = CNN_Net(input_dim).to(self.device) # create a CNN_Net model\n",
        "        \n",
        "        # create training, testing, validation set\n",
        "        self.train_dataset = MiniImageNet(train_data)\n",
        "        self.val_dataset = MiniImageNet(val_data)\n",
        "        self.test_dataset = MiniImageNet(test_data)\n",
        "\n",
        "        # optimizer\n",
        "        self.optimizer = torch.optim.Adam(self.cnn_net.parameters(), lr=0.001)\n",
        "        # learning rate scheduler\n",
        "        self.scheduler = optim.lr_scheduler.StepLR(\n",
        "            self.optimizer, 1, gamma=0.5, last_epoch=-1)\n",
        "        print(\"useage：\", self.device)\n",
        "\n",
        "    # function that calculates the euclidean distance\n",
        "    def cal_euc_distance(self, query_z, center,K_way, N_query):\n",
        "        \"\"\"\n",
        "            compute distance between query_z and center\n",
        "            query_z : (K_way*N_query,z_dim)\n",
        "            center : (K_way,z_dim)\n",
        "        \"\"\"\n",
        "        center = center.unsqueeze(0).expand(\n",
        "            K_way*N_query, K_way, self.z_dim)  # (K_way*N_query,K_way,z_dim)\n",
        "        query_z = query_z.unsqueeze(1).expand(\n",
        "            K_way*N_query, K_way, self.z_dim)  # (K_way*N_query,K_way,z_dim)\n",
        "\n",
        "        return torch.pow(query_z-center, 2).sum(2)  # (K_way*N_query,K_way)\n",
        "\n",
        "    # function that calculates the loss and accuracy\n",
        "    def loss_acc(self, query_z, center, K_way, N_query):\n",
        "        \"\"\"\n",
        "            compute loss & accuracy\n",
        "            query_z : (K_way*N_query,z_dim)\n",
        "            center : (K_way,z_dim)\n",
        "        \"\"\"\n",
        "        # create a target index\n",
        "        target_inds = torch.arange(0, K_way).view(K_way, 1).expand(\n",
        "            K_way, N_query).long().to(self.device) # shape=(K_way, N_query)\n",
        "        \n",
        "        distance = self.cal_euc_distance(query_z, center,K_way, N_query)    # (K_way*N_query,K_way) \n",
        "        predict_label = torch.argmin(distance, dim=1)  # (K_way*N_query) # predicted labels\n",
        "\n",
        "        acc = torch.eq(target_inds.contiguous().view(-1),\n",
        "                        predict_label).float().mean() # accuracy\n",
        "\n",
        "        loss = F.log_softmax(-distance, dim=1).view(K_way,\n",
        "                                                    N_query, K_way)  # (K_way,N_query,K_way)\n",
        "        loss = - \\\n",
        "            loss.gather(dim=2, index=target_inds.unsqueeze(2)).view(-1).mean()\n",
        "        return loss, acc\n",
        "\n",
        "    def set_forward_loss(self, K_way, N_shot, N_query,sample_datas):\n",
        "        \"\"\"\n",
        "            sample_datas： shape(K_way*(N_shot+N_query),3,84,84)\n",
        "        \"\"\"\n",
        "\n",
        "        # convert support set&query set to vectors\n",
        "        z = self.cnn_net(sample_datas) # shape=(K_way*(N_shot+N_query),z_dim) \n",
        "        # convert to 2D\n",
        "        z = z.view(K_way,N_shot+N_query,-1) # shape = (K_way,N_shot+N_query,1600)\n",
        "        \n",
        "        support_z = z[:,:N_shot] # support set's vector; shape=(K_way,N_shot,1600)\n",
        "        query_z = z[:,N_shot:].contiguous().view(K_way*N_query,-1) # Query set's vector; shape=(K_way*N_query,1600)\n",
        "        \n",
        "        center = torch.mean(support_z, dim=1) # compute support set centorid，shape=(K_way,1600)\n",
        "        return self.loss_acc(query_z, center,K_way,N_query)\n",
        "\n",
        "    def train(self, epochs, epoch_size):\n",
        "        \"\"\"\n",
        "            training，randomly select classes with k samples。\n",
        "        \"\"\"\n",
        "        K_way = 20\n",
        "        N_shot = 5\n",
        "        N_query = 15\n",
        "\n",
        "        self.cnn_net.train()\n",
        "        # create a sampler for training\n",
        "        train_sampler = CategoriesSampler(train_data, epoch_size,K_way,N_shot+N_query)\n",
        "\n",
        "        train_loader = DataLoader(dataset=self.train_dataset, batch_sampler=train_sampler,\n",
        "                                    num_workers=16, pin_memory=True)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            for i,batch_data in enumerate(train_loader):\n",
        "                imgs,_ = batch_data[0].to(self.device),batch_data[1]\n",
        "                loss, acc = self.set_forward_loss(K_way,N_shot,N_query,imgs)\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "            self.scheduler.step()\n",
        "\n",
        "            val_acc1 = self.eval_model(val_data,self.val_dataset,5,1,15,600) \n",
        "            val_acc2 = self.eval_model(val_data,self.val_dataset,5,5,15,600) \n",
        "            \n",
        "            test_acc1 = self.eval_model(test_data,self.test_dataset,5,1,15,600)\n",
        "            \n",
        "            test_acc2 = self.eval_model(test_data,self.test_dataset,5,5,15,600) \n",
        "\n",
        "            print(\"Training set：1-shot：{:.4},5-shot：{:.4}\".format(val_acc1,val_acc2))\n",
        "            \n",
        "            print(\"Testing set：1-shot：{:.4},5-shot：{:.4}\".format(test_acc1,test_acc2))\n",
        "            \n",
        "    # evuluate model\n",
        "    def eval_model(self,datas,data_set,K_way,N_shot,N_query, eval_step):\n",
        "        self.cnn_net.eval()\n",
        "        batch_sampler = CategoriesSampler(datas,eval_step,K_way,N_shot+N_query)\n",
        "        data_loader = DataLoader(dataset=data_set, batch_sampler=batch_sampler,\n",
        "                                            num_workers=16, pin_memory=True)\n",
        "        accs = []\n",
        "        losses = []\n",
        "        for i,batch_data in enumerate(data_loader):\n",
        "            imgs,_ = batch_data[0].to(self.device),batch_data[1]\n",
        "            loss, acc = self.set_forward_loss(K_way,N_shot,N_query,imgs)\n",
        "            accs.append(acc.item())\n",
        "            losses.append(loss.item())\n",
        "        self.cnn_net.train()\n",
        "        return sum(accs)/eval_step"
      ],
      "metadata": {
        "id": "HkDsKIQl7sTX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Prototypicl_Net(3) # input_dim,K_way, N_shot, N_query\n",
        "#net.train(50, 2000)\n",
        "net.train(1, 2000)"
      ],
      "metadata": {
        "id": "9KkXNRv8jAJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d40011b-f519-4da6-c612-dd6e56c14509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "useage： cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qqX6DXHYjAGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OkFnCaDBjADP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fH_BTBkKjAAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------"
      ],
      "metadata": {
        "id": "PaRf9dvUr0eS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D2z2tLSTi_9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IQLozubCi_6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N2BHqDkFi_3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DkQE70xTi_01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1MGW5bYsi_xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zwD7K8uei_ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X_auf19ci_rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cMk695lUi_pP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}